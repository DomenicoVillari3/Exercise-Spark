{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d7022e-4977-4636-8476-da302fafc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11d9662e-13a0-4cfe-a569-04a5edf6453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"BasicSparkExample\") .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f37fa487-16a3-4961-b0a0-6a1e7f032c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n",
      "[2, 4, 6, 8, 10]\n",
      "[2, 4]\n"
     ]
    }
   ],
   "source": [
    "# Create an RDD from a Python list\n",
    "data = [1, 2, 3, 4, 5]\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "# Show the contents of the RDD\n",
    "print(rdd.collect())\n",
    "\n",
    "mapped_rdd=rdd.map(lambda x:x*2)\n",
    "print(mapped_rdd.collect())\n",
    "\n",
    "filtered_rdd=rdd.filter(lambda x:x%2==0)\n",
    "print(filtered_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb254fab-2e34-4529-b763-02fd10944de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GENERATE RANDOM DATA ON CSV FILE\n",
    "# Python3 code to demonstrate working of\n",
    "# Random K dates in Range\n",
    "# Using choices() + timedelta() + loop\n",
    "from datetime import date, timedelta\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def get_random_dates(k):\n",
    "    # Python3 code to demonstrate working of\n",
    "    # Random K dates in Range\n",
    "    # Using randrange() + timedelta() + loop\n",
    "    \n",
    "    # initializing dates ranges \n",
    "    test_date1, test_date2 = date(2023, 1, 1), date(2023, 12, 31)\n",
    "    \n",
    "    # printing dates \n",
    "    #print(\"The original range : \" + str(test_date1) + \" \" + str(test_date2))\n",
    "    \n",
    "    # initializing K\n",
    "    K = k\n",
    "    \n",
    "    # getting days between dates\n",
    "    dates_bet = test_date2 - test_date1\n",
    "    total_days = dates_bet.days\n",
    "    \n",
    "    res = []\n",
    "    for idx in range(K):\n",
    "        random.seed(a=None)\n",
    "        \n",
    "        # getting random days\n",
    "        randay = random.randrange(total_days)\n",
    "        \n",
    "        # getting random dates \n",
    "        res.append(test_date1 + timedelta(days=randay))\n",
    "    \n",
    "    # printing \n",
    "    #print(\"K random dates in range : \" + str(res))\n",
    "\n",
    "    return res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bbe6675-41fd-46ec-b33f-eabe7dbcddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples=100\n",
    "dates=get_random_dates(100)\n",
    "\n",
    "data=[]\n",
    "columns = [\"TID\", \"UID\", \"val\", \"time\"]\n",
    "for i in range(n_samples):\n",
    "    row=[]\n",
    "    row.append(random.randint(1,70))\n",
    "    row.append(101+i)\n",
    "    row.append(round(random.uniform(50, 250), 2))\n",
    "    row.append(dates[i])\n",
    "\n",
    "    data.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e72cb1c-0a56-4f4e-86de-04101c550b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------+----------+\n",
      "|TID|UID|   val|      time|\n",
      "+---+---+------+----------+\n",
      "| 47|101|223.73|2023-09-09|\n",
      "| 60|102|211.12|2023-12-25|\n",
      "|  3|103|115.09|2023-06-24|\n",
      "| 66|104|193.98|2023-07-04|\n",
      "| 27|105|176.57|2023-01-10|\n",
      "| 22|106|177.37|2023-12-01|\n",
      "| 39|107|190.43|2023-10-22|\n",
      "| 66|108|118.06|2023-10-28|\n",
      "| 12|109|127.62|2023-03-29|\n",
      "| 22|110|102.79|2023-03-29|\n",
      "| 18|111|234.08|2023-02-26|\n",
      "| 47|112| 92.44|2023-06-18|\n",
      "|  6|113|145.41|2023-02-16|\n",
      "| 45|114|130.82|2023-03-09|\n",
      "| 45|115| 82.98|2023-10-06|\n",
      "|  2|116|146.82|2023-02-22|\n",
      "| 13|117|217.89|2023-02-16|\n",
      "| 27|118|217.31|2023-02-25|\n",
      "| 55|119|106.63|2023-10-29|\n",
      "| 35|120|134.45|2023-02-01|\n",
      "+---+---+------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+---+------+----------+\n",
      "|TID|UID|   val|      time|\n",
      "+---+---+------+----------+\n",
      "| 47|101|223.73|2023-09-09|\n",
      "| 60|102|211.12|2023-12-25|\n",
      "|  3|103|115.09|2023-06-24|\n",
      "| 66|104|193.98|2023-07-04|\n",
      "| 27|105|176.57|2023-01-10|\n",
      "| 22|106|177.37|2023-12-01|\n",
      "| 39|107|190.43|2023-10-22|\n",
      "| 66|108|118.06|2023-10-28|\n",
      "| 12|109|127.62|2023-03-29|\n",
      "| 22|110|102.79|2023-03-29|\n",
      "| 18|111|234.08|2023-02-26|\n",
      "|  6|113|145.41|2023-02-16|\n",
      "| 45|114|130.82|2023-03-09|\n",
      "|  2|116|146.82|2023-02-22|\n",
      "| 13|117|217.89|2023-02-16|\n",
      "| 27|118|217.31|2023-02-25|\n",
      "| 55|119|106.63|2023-10-29|\n",
      "| 35|120|134.45|2023-02-01|\n",
      "| 37|121|208.28|2023-08-12|\n",
      "| 37|122|108.21|2023-06-23|\n",
      "+---+---+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'groupByKey'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(df\u001b[38;5;241m.\u001b[39mval \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      4\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m----> 5\u001b[0m grouped_df\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupByKey\u001b[49m()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:3123\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3090\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   3091\u001b[0m \n\u001b[1;32m   3092\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3120\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[1;32m   3121\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 3123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   3124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   3125\u001b[0m     )\n\u001b[1;32m   3126\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   3127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'groupByKey'"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data, columns)\n",
    "df.show()\n",
    "filtered_df = df.filter(df.val > 100)\n",
    "filtered_df.show()\n",
    "grouped_df=df.groupBy(\"UID\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f4ee99c-a3ca-46d8-b3ca-8e70c811d181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[47, 101, 223.73, datetime.date(2023, 9, 9)], [60, 102, 211.12, datetime.date(2023, 12, 25)], [3, 103, 115.09, datetime.date(2023, 6, 24)], [66, 104, 193.98, datetime.date(2023, 7, 4)], [27, 105, 176.57, datetime.date(2023, 1, 10)], [22, 106, 177.37, datetime.date(2023, 12, 1)], [39, 107, 190.43, datetime.date(2023, 10, 22)], [66, 108, 118.06, datetime.date(2023, 10, 28)], [12, 109, 127.62, datetime.date(2023, 3, 29)], [22, 110, 102.79, datetime.date(2023, 3, 29)], [18, 111, 234.08, datetime.date(2023, 2, 26)], [47, 112, 92.44, datetime.date(2023, 6, 18)], [6, 113, 145.41, datetime.date(2023, 2, 16)], [45, 114, 130.82, datetime.date(2023, 3, 9)], [45, 115, 82.98, datetime.date(2023, 10, 6)], [2, 116, 146.82, datetime.date(2023, 2, 22)], [13, 117, 217.89, datetime.date(2023, 2, 16)], [27, 118, 217.31, datetime.date(2023, 2, 25)], [55, 119, 106.63, datetime.date(2023, 10, 29)], [35, 120, 134.45, datetime.date(2023, 2, 1)], [37, 121, 208.28, datetime.date(2023, 8, 12)], [37, 122, 108.21, datetime.date(2023, 6, 23)], [1, 123, 53.75, datetime.date(2023, 7, 26)], [51, 124, 180.51, datetime.date(2023, 10, 26)], [56, 125, 192.88, datetime.date(2023, 9, 19)], [69, 126, 169.89, datetime.date(2023, 11, 17)], [8, 127, 219.95, datetime.date(2023, 5, 23)], [22, 128, 200.59, datetime.date(2023, 5, 9)], [48, 129, 138.96, datetime.date(2023, 9, 28)], [63, 130, 146.55, datetime.date(2023, 9, 13)], [47, 131, 112.64, datetime.date(2023, 4, 21)], [38, 132, 143.1, datetime.date(2023, 5, 25)], [51, 133, 245.07, datetime.date(2023, 1, 22)], [23, 134, 223.69, datetime.date(2023, 11, 11)], [32, 135, 249.32, datetime.date(2023, 5, 12)], [35, 136, 202.65, datetime.date(2023, 10, 16)], [51, 137, 53.38, datetime.date(2023, 7, 24)], [65, 138, 173.69, datetime.date(2023, 11, 13)], [14, 139, 228.65, datetime.date(2023, 3, 30)], [13, 140, 236.64, datetime.date(2023, 5, 10)], [51, 141, 82.54, datetime.date(2023, 5, 23)], [24, 142, 223.19, datetime.date(2023, 10, 28)], [24, 143, 164.16, datetime.date(2023, 10, 25)], [17, 144, 128.49, datetime.date(2023, 11, 21)], [64, 145, 154.5, datetime.date(2023, 2, 18)], [34, 146, 64.52, datetime.date(2023, 9, 21)], [3, 147, 54.33, datetime.date(2023, 9, 8)], [57, 148, 143.81, datetime.date(2023, 5, 30)], [16, 149, 207.38, datetime.date(2023, 6, 3)], [33, 150, 63.68, datetime.date(2023, 1, 14)], [64, 151, 236.52, datetime.date(2023, 3, 13)], [68, 152, 211.12, datetime.date(2023, 9, 4)], [13, 153, 198.38, datetime.date(2023, 3, 22)], [10, 154, 78.61, datetime.date(2023, 11, 25)], [14, 155, 127.07, datetime.date(2023, 9, 23)], [14, 156, 94.94, datetime.date(2023, 8, 24)], [60, 157, 219.88, datetime.date(2023, 10, 1)], [56, 158, 114.4, datetime.date(2023, 1, 19)], [41, 159, 197.75, datetime.date(2023, 5, 6)], [35, 160, 201.27, datetime.date(2023, 5, 7)], [32, 161, 216.46, datetime.date(2023, 4, 18)], [56, 162, 148.8, datetime.date(2023, 12, 23)], [34, 163, 105.13, datetime.date(2023, 7, 25)], [9, 164, 236.48, datetime.date(2023, 9, 17)], [67, 165, 83.66, datetime.date(2023, 11, 7)], [54, 166, 71.63, datetime.date(2023, 6, 23)], [32, 167, 172.97, datetime.date(2023, 11, 22)], [67, 168, 188.0, datetime.date(2023, 10, 29)], [45, 169, 205.12, datetime.date(2023, 11, 22)], [49, 170, 87.1, datetime.date(2023, 2, 5)], [6, 171, 131.25, datetime.date(2023, 12, 8)], [49, 172, 249.35, datetime.date(2023, 9, 28)], [62, 173, 54.66, datetime.date(2023, 8, 25)], [4, 174, 158.99, datetime.date(2023, 6, 22)], [4, 175, 143.47, datetime.date(2023, 6, 28)], [26, 176, 62.56, datetime.date(2023, 6, 5)], [4, 177, 66.38, datetime.date(2023, 7, 5)], [35, 178, 151.46, datetime.date(2023, 7, 29)], [12, 179, 56.65, datetime.date(2023, 8, 19)], [57, 180, 119.77, datetime.date(2023, 5, 19)], [10, 181, 132.69, datetime.date(2023, 12, 19)], [67, 182, 151.66, datetime.date(2023, 1, 21)], [36, 183, 59.99, datetime.date(2023, 10, 7)], [61, 184, 222.5, datetime.date(2023, 1, 4)], [26, 185, 100.58, datetime.date(2023, 8, 23)], [56, 186, 164.45, datetime.date(2023, 1, 13)], [1, 187, 192.35, datetime.date(2023, 5, 19)], [27, 188, 241.72, datetime.date(2023, 10, 5)], [1, 189, 102.29, datetime.date(2023, 8, 5)], [7, 190, 199.74, datetime.date(2023, 4, 4)], [19, 191, 142.83, datetime.date(2023, 8, 9)], [18, 192, 165.83, datetime.date(2023, 2, 18)], [6, 193, 233.05, datetime.date(2023, 3, 17)], [45, 194, 207.53, datetime.date(2023, 8, 25)], [63, 195, 98.83, datetime.date(2023, 12, 8)], [6, 196, 187.85, datetime.date(2023, 9, 23)], [14, 197, 174.16, datetime.date(2023, 3, 20)], [29, 198, 223.99, datetime.date(2023, 2, 26)], [35, 199, 204.49, datetime.date(2023, 7, 7)], [7, 200, 93.44, datetime.date(2023, 6, 21)]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[(56, 620.53), (8, 219.95), (48, 138.96), (32, 638.75), (24, 387.35), (64, 391.02), (16, 207.38), (1, 348.39), (65, 173.69), (17, 128.49), (57, 263.58), (33, 63.68), (41, 197.75), (9, 236.48), (49, 336.45), (66, 312.03999999999996), (18, 399.91), (2, 146.82), (34, 169.64999999999998), (10, 211.3), (26, 163.14), (3, 169.42000000000002), (27, 635.6), (35, 894.32), (51, 561.5), (67, 423.31999999999994), (19, 142.83), (60, 431.0), (12, 184.27), (68, 211.12), (4, 368.84000000000003), (36, 59.99), (45, 626.45), (13, 652.91), (37, 316.49), (69, 169.89), (61, 222.5), (29, 223.99), (22, 480.75), (6, 697.56), (38, 143.1), (14, 624.8199999999999), (54, 71.63), (62, 54.66), (47, 428.80999999999995), (39, 190.43), (55, 106.63), (63, 245.38), (23, 223.69), (7, 293.18)]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(data)\n",
    "print(rdd.collect())   \n",
    "filtered_rdd = rdd.filter(lambda row: row[2] > 100)\n",
    "#print(filtered_rdd.collect())\n",
    "\n",
    "\n",
    "print(\"\\n\\n\\n\")\n",
    "\n",
    "rdd_pairs = rdd.map(lambda row: (row[0], row[2])) \n",
    "#grouped_rdd=rdd_pairs.groupByKey()\n",
    "#print([(k, list(v)) for k, v in grouped_rdd.collect()])\n",
    "\n",
    "reduced_rdd=rdd_pairs.reduceByKey(lambda x,y:x+y)\n",
    "print(reduced_rdd.collect())\n",
    "print(\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf7a52-b624-4e82-875a-08a23854ecff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad89d7-e94d-4786-bb1a-bf37265868ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
